{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_phase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcfoqq0+zuSSY3R/urGBxn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravanisasu/10k-sample/blob/main/CNN_10kreports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTMNcHpsUI_a",
        "outputId": "92628c1e-4936-4b19-e4fd-443fbd02f3f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/sravanisasu/10k-sample"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '10k-sample'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9554 (delta 0), reused 1 (delta 0), pack-reused 9548\u001b[K\n",
            "Receiving objects: 100% (9554/9554), 158.13 MiB | 19.51 MiB/s, done.\n",
            "Resolving deltas: 100% (335/335), done.\n",
            "Checking out files: 100% (10019/10019), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-MWsoiWOC8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ae2d16-d989-491e-ebb1-c1137ff6cc27"
      },
      "source": [
        "# Importing the required packages\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "import os\n",
        "import re\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7M9JpeG0CYa"
      },
      "source": [
        "#Define file paths required for the model\n",
        "\n",
        "# embedding bin file\n",
        "embed_file = \"/content/sim.expand.200d.vec\"\n",
        "\n",
        "#Define Hyper parameters\n",
        "max_inp_len = 20000\n",
        "# the dimension of vectors to be used\n",
        "embed_dim = 200\n",
        "rounding = 6\n",
        "# filter sizes of the different conv layers \n",
        "filter_sizes = [3,4,5]\n",
        "num_filters = 1\n",
        "pool_size = 32\n",
        "# dropout probability\n",
        "drop = 0.5\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "epochs = 30"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DbBN4tosBE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff8eda3-3f48-42e6-897f-628d8ab700d4"
      },
      "source": [
        "#define embedding dictionary and embed matrix for the vocabulary\n",
        "embeddings_dic = dict()\n",
        "f = open(embed_file,encoding='utf8')\n",
        "with open(embed_file, 'r', encoding='utf-8') as e_file:\n",
        "  for line in e_file:\n",
        "    splitlines = line.split()\n",
        "    word = splitlines[0].strip()\n",
        "    coefs = np.asarray(splitlines[1:], dtype='float32')\n",
        "    embeddings_dic[word] = coefs\n",
        "\n",
        "print(\"length of embedding dictionary\",len(embeddings_dic))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of embedding dictionary 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqa1tA-lt6e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf3c27a-057b-48d1-e8ac-380979541683"
      },
      "source": [
        "vocabulary_size = len(embeddings_dic.keys())\n",
        "embed_token = Tokenizer()\n",
        "embed_token.fit_on_texts(embeddings_dic.keys())\n",
        "embedding_matrix = np.zeros((vocabulary_size, embed_dim))\n",
        "for word, index in embed_token.word_index.items():\n",
        "  embedding_matrix[index] = embeddings_dic.get(word)\n",
        "print(\"embedding_matrix dimension\",len(embedding_matrix),len(embedding_matrix[0]))\n",
        "print(\"no of token in the tokenizer\",len(embed_token.word_index) + 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding_matrix dimension 70428 200\n",
            "no of token in the tokenizer 70428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laF6m-NotXFw"
      },
      "source": [
        "#function to pre process the document\n",
        "def process_doc(path_file,embed_token) :\n",
        "\n",
        "  #tokenizing the words \n",
        "  with open(path_file,'r', encoding='utf-8') as tok_file :\n",
        "    file_words = list(tok_file)[0].split()\n",
        "    \n",
        "  #removing the stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_words = []  \n",
        "  for word in file_words: \n",
        "      if word not in stop_words and word.isalpha(): \n",
        "          filtered_words.append(word)\n",
        "\n",
        "  # applying stemming using PorterStemmer\n",
        "\n",
        "  p_stemmer = PorterStemmer()\n",
        "  stem_words=[]\n",
        "  for word in filtered_words:\n",
        "    stem_words.append(p_stemmer.stem(word))\n",
        "    \n",
        "  #tokenizing the words using the embed token\n",
        "  tokens=[]\n",
        "  for word in stem_words:\n",
        "    try:\n",
        "      tokens.append(embed_token.word_index[word])\n",
        "    except:\n",
        "      tokens.append(1)\n",
        "\n",
        "  tokens.extend([0]*(max_inp_len-len(tokens)))\n",
        "\n",
        "  return tokens[:20000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q4J5yKMfxDP"
      },
      "source": [
        "#input dataset\n",
        "def input_data(meta_file):\n",
        "  documents = list()\n",
        "  with open(meta_file,'r', encoding='utf-8') as m_file :\n",
        "    year = meta_file.split('/')[3].split('.')[0]\n",
        "    dir_path = os.path.dirname(meta_file) + '/' +year+'.tok'\n",
        "    for line in m_file.readlines():\n",
        "      inp_path_file = dir_path +'/'+ line.split()[0] + '.mda'\n",
        "      # get tokens for the doc\n",
        "      tokens = process_doc(inp_path_file,embed_token)\n",
        "      documents.append(tokens)\n",
        "  return documents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVi-HHNCPHkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b68be24-b269-4140-e030-8598ae5815cd"
      },
      "source": [
        "input_X = input_data('/content/10k-sample/2007.meta.txt')\n",
        "print(len(input_X))\n",
        "input_X.extend(input_data('/content/10k-sample/2008.meta.txt'))\n",
        "print(len(input_X))\n",
        "input_X.extend(input_data('/content/10k-sample/2009.meta.txt'))\n",
        "print(len(input_X))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2495\n",
            "5004\n",
            "7571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCdDHfYt3l7"
      },
      "source": [
        "#output dataset\n",
        "def output_data(out_path_file):\n",
        "  output=[]\n",
        "  with open(out_path_file,'r', encoding='utf-8') as out_file :\n",
        "    for line in out_file.readlines():\n",
        "      output.append(float(line.split()[0]))\n",
        "  return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp_iyrbHQXR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea07414-0002-42e3-d30a-8721ae18c8dd"
      },
      "source": [
        "output_Y = output_data('/content/10k-sample/2007.logvol.+12.txt')\n",
        "print(len(output_Y))\n",
        "output_Y.extend(output_data('/content/10k-sample/2008.logvol.+12.txt'))\n",
        "print(len(output_Y))\n",
        "output_Y.extend(output_data('/content/10k-sample/2009.logvol.+12.txt'))\n",
        "print(len(output_Y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2495\n",
            "5004\n",
            "7571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lar37ukkqj-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad10130-c7be-4431-a08d-928f0da0667c"
      },
      "source": [
        "print(np.array(input_X).shape)\n",
        "#np.array(output_Y).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7571, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOmvEheA_Mw"
      },
      "source": [
        "def define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,pool_size,drop,learning_rate):\n",
        "  \n",
        "  # input and embedding matrix\n",
        "  inputs = Input(shape=(max_inp_len,))\n",
        "  embedding = Embedding(vocabulary_size, embed_dim, weights=[embedding_matrix],trainable = False)(inputs)\n",
        "\n",
        "  custom_objects={'leaky_relu': tf.nn.leaky_relu}\n",
        "\n",
        "  # channel 1 convolution and local max-pooling\n",
        "  convolution_1 = Conv1D(filters=num_filters, kernel_size=filter_sizes[0], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_1 = MaxPooling1D(pool_size=pool_size)(convolution_1)\n",
        "  \n",
        "\t# channel 2 convolution and local max-pooling\n",
        "  convolution_4 = Conv1D(filters=num_filters, kernel_size=filter_sizes[1], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_2 = MaxPooling1D(pool_size=pool_size)(convolution_4)\n",
        "  \n",
        "  # channel 3 convolution and local max-pooling\n",
        "  convolution_5 = Conv1D(filters=num_filters, kernel_size=filter_sizes[2], activation=custom_objects['leaky_relu'])(embedding)\n",
        "  pool_3 = MaxPooling1D(pool_size=pool_size)(convolution_5)\n",
        "  \n",
        "  # merge and dropout\n",
        "  merged = concatenate([pool_1,pool_2,pool_3],axis=1)\n",
        "  drop_out = Dropout(drop)(merged)\n",
        "  flat = Flatten()(drop_out)\n",
        "\n",
        "  # 2 fully connected layers\n",
        "  dense1 = Dense(200, activation=custom_objects['leaky_relu'])(flat)\n",
        "  outputs = Dense(1, activation=custom_objects['leaky_relu'])(dense1)\n",
        "  model = Model(inputs=[inputs], outputs=outputs)\n",
        "    \n",
        "  opt = optimizers.SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss='mse', optimizer=opt, metrics=[RootMeanSquaredError()])\n",
        "\n",
        "\t# summarize\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeyM-2XMBi7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345e2e42-72a0-4978-a928-cb5c4fa55787"
      },
      "source": [
        "input_X = np.array(input_X)\n",
        "output_Y = np.array(output_Y)\n",
        "#output_Y = tf.keras.utils.normalize(output_Y)\n",
        "print(input_X.shape)\n",
        "print(output_Y.shape)\n",
        "from sklearn import model_selection as ms\n",
        "\n",
        "x_train, x_test, y_train, y_test = ms.train_test_split(input_X, output_Y, random_state = 1 ,test_size=0.33)\n",
        "\n",
        "print(\"total input shape\",input_X.shape)\n",
        "print(\"total output shape\",output_Y.shape)\n",
        "print(\"training input shape\",x_train.shape)\n",
        "print(\"training output shape\",y_train.shape)\n",
        "print(\"testing input shape\",x_test.shape)\n",
        "print(\"testing output shape\",y_test.shape)\n",
        "\n",
        "# define model\n",
        "model = define_model(max_inp_len,vocabulary_size,embed_dim,filter_sizes,num_filters,64,drop,learning_rate)\n",
        "# fit mode\n",
        "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs)\n",
        "model.save('model.h5')\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7571, 20000)\n",
            "(7571,)\n",
            "total input shape (7571, 20000)\n",
            "total output shape (7571,)\n",
            "training input shape (5072, 20000)\n",
            "training output shape (5072,)\n",
            "testing input shape (2499, 20000)\n",
            "testing output shape (2499,)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20000, 200)   14085600    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 19998, 1)     601         embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 19997, 1)     801         embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 19996, 1)     1001        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 312, 1)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 312, 1)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 312, 1)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 936, 1)       0           max_pooling1d[0][0]              \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 936, 1)       0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 936)          0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 200)          187400      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            201         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 14,275,604\n",
            "Trainable params: 190,004\n",
            "Non-trainable params: 14,085,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 26s 259ms/step - loss: 9.0876 - root_mean_squared_error: 3.0146\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 27s 260ms/step - loss: 0.9450 - root_mean_squared_error: 0.9721\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 27s 263ms/step - loss: 0.4067 - root_mean_squared_error: 0.6377\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 27s 266ms/step - loss: 0.3947 - root_mean_squared_error: 0.6283\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3751 - root_mean_squared_error: 0.6125\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 27s 267ms/step - loss: 0.3754 - root_mean_squared_error: 0.6127\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3633 - root_mean_squared_error: 0.6027\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3514 - root_mean_squared_error: 0.5928\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3473 - root_mean_squared_error: 0.5894\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3453 - root_mean_squared_error: 0.5877\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3375 - root_mean_squared_error: 0.5809\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3365 - root_mean_squared_error: 0.5800\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3345 - root_mean_squared_error: 0.5783\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3246 - root_mean_squared_error: 0.5697\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3252 - root_mean_squared_error: 0.5703\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 27s 267ms/step - loss: 0.3224 - root_mean_squared_error: 0.5678\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3255 - root_mean_squared_error: 0.5706\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3197 - root_mean_squared_error: 0.5654\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3073 - root_mean_squared_error: 0.5543\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 27s 267ms/step - loss: 0.3124 - root_mean_squared_error: 0.5589\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 27s 268ms/step - loss: 0.3066 - root_mean_squared_error: 0.5537\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 27s 267ms/step - loss: 0.3114 - root_mean_squared_error: 0.5581\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3118 - root_mean_squared_error: 0.5584\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3002 - root_mean_squared_error: 0.5479\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3073 - root_mean_squared_error: 0.5543\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3059 - root_mean_squared_error: 0.5531\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3055 - root_mean_squared_error: 0.5527\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3005 - root_mean_squared_error: 0.5482\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3034 - root_mean_squared_error: 0.5508\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 27s 269ms/step - loss: 0.3084 - root_mean_squared_error: 0.5554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjyXD9-Y9A33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cc4347-7dfc-4d47-cb11-63088585e6f3"
      },
      "source": [
        "loss_T, RMSE_T = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train Error: %f' % (RMSE_T))\n",
        " \n",
        "# evaluate model on test dataset dataset\n",
        "loss_V, RMSE_V = model.evaluate(x_test,y_test, verbose=0)\n",
        "print('Test Error: %f' % (RMSE_V))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Error: 0.510544\n",
            "Test Error: 0.510756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daLyVCcEzjmJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "479e8ce7-7714-40ec-8fdb-2d2b3dbeb6ad"
      },
      "source": [
        "print(history.history.keys())\n",
        "fig, ax1 = plt.subplots()\n",
        "epochs_arr =[i for i in range(0,epochs)]\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('RMSE', color=color)\n",
        "ax1.plot(epochs_arr, history.history['root_mean_squared_error'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "plt.show()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'root_mean_squared_error'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}